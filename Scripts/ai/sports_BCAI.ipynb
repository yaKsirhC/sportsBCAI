{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 500\n",
    "X,y = make_classification(n_samples=n_samples, n_classes=2, n_features=4)\n",
    "X=torch.from_numpy(X).type(torch.float)\n",
    "y=torch.from_numpy(y).type(torch.float)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.2 )\n",
    "X_train =  X_train\n",
    "X_test = X_test\n",
    "y_train = y_train.unsqueeze(1)\n",
    "y_test = y_test.unsqueeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test_mod(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_features=4, out_features=16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=16, out_features=16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=16, out_features=16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=16, out_features=16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=16, out_features=1),\n",
    "        )\n",
    "    def forward(self,X):\n",
    "        return self.layers(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = test_mod()\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optim = torch.optim.SGD(model.parameters(), lr=.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 | loss: 0.6965557932853699\n",
      "epoch: 10 | loss: 0.6965557932853699\n",
      "epoch: 20 | loss: 0.6965557932853699\n",
      "epoch: 30 | loss: 0.6965557932853699\n",
      "epoch: 40 | loss: 0.6965557336807251\n",
      "epoch: 50 | loss: 0.6965557336807251\n",
      "epoch: 60 | loss: 0.6965557336807251\n",
      "epoch: 70 | loss: 0.6965557336807251\n",
      "epoch: 80 | loss: 0.6965557336807251\n",
      "epoch: 90 | loss: 0.6965557336807251\n",
      "epoch: 100 | loss: 0.6965556144714355\n",
      "epoch: 110 | loss: 0.6965556144714355\n",
      "epoch: 120 | loss: 0.6965556144714355\n",
      "epoch: 130 | loss: 0.6965556144714355\n",
      "epoch: 140 | loss: 0.6965556144714355\n",
      "epoch: 150 | loss: 0.6965556144714355\n",
      "epoch: 160 | loss: 0.6965556144714355\n",
      "epoch: 170 | loss: 0.6965556144714355\n",
      "epoch: 180 | loss: 0.6965556144714355\n",
      "epoch: 190 | loss: 0.696555495262146\n",
      "epoch: 200 | loss: 0.696555495262146\n",
      "epoch: 210 | loss: 0.696555495262146\n",
      "epoch: 220 | loss: 0.6965553760528564\n",
      "epoch: 230 | loss: 0.6965553760528564\n",
      "epoch: 240 | loss: 0.6965553760528564\n",
      "epoch: 250 | loss: 0.6965553760528564\n",
      "epoch: 260 | loss: 0.6965553760528564\n",
      "epoch: 270 | loss: 0.6965553760528564\n",
      "epoch: 280 | loss: 0.6965553760528564\n",
      "epoch: 290 | loss: 0.6965553760528564\n",
      "epoch: 300 | loss: 0.6965553760528564\n",
      "epoch: 310 | loss: 0.6965553164482117\n",
      "epoch: 320 | loss: 0.6965553164482117\n",
      "epoch: 330 | loss: 0.6965553164482117\n",
      "epoch: 340 | loss: 0.6965553164482117\n",
      "epoch: 350 | loss: 0.6965553164482117\n",
      "epoch: 360 | loss: 0.6965553164482117\n",
      "epoch: 370 | loss: 0.6965552568435669\n",
      "epoch: 380 | loss: 0.6965552568435669\n",
      "epoch: 390 | loss: 0.6965552568435669\n",
      "epoch: 400 | loss: 0.6965552568435669\n",
      "epoch: 410 | loss: 0.6965552568435669\n",
      "epoch: 420 | loss: 0.6965552568435669\n",
      "epoch: 430 | loss: 0.6965552568435669\n",
      "epoch: 440 | loss: 0.6965552568435669\n",
      "epoch: 450 | loss: 0.6965551972389221\n",
      "epoch: 460 | loss: 0.6965551972389221\n",
      "epoch: 470 | loss: 0.6965551972389221\n",
      "epoch: 480 | loss: 0.6965551972389221\n",
      "epoch: 490 | loss: 0.6965551972389221\n",
      "epoch: 500 | loss: 0.6965551972389221\n",
      "epoch: 510 | loss: 0.6965551972389221\n",
      "epoch: 520 | loss: 0.6965550184249878\n",
      "epoch: 530 | loss: 0.6965550184249878\n",
      "epoch: 540 | loss: 0.6965550184249878\n",
      "epoch: 550 | loss: 0.6965550184249878\n",
      "epoch: 560 | loss: 0.6965550184249878\n",
      "epoch: 570 | loss: 0.6965550184249878\n",
      "epoch: 580 | loss: 0.6965550184249878\n",
      "epoch: 590 | loss: 0.696554958820343\n",
      "epoch: 600 | loss: 0.696554958820343\n",
      "epoch: 610 | loss: 0.696554958820343\n",
      "epoch: 620 | loss: 0.696554958820343\n",
      "epoch: 630 | loss: 0.696554958820343\n",
      "epoch: 640 | loss: 0.6965548992156982\n",
      "epoch: 650 | loss: 0.6965548992156982\n",
      "epoch: 660 | loss: 0.6965548992156982\n",
      "epoch: 670 | loss: 0.6965547800064087\n",
      "epoch: 680 | loss: 0.6965548992156982\n",
      "epoch: 690 | loss: 0.6965548992156982\n",
      "epoch: 700 | loss: 0.6965547204017639\n",
      "epoch: 710 | loss: 0.6965547800064087\n",
      "epoch: 720 | loss: 0.6965547204017639\n",
      "epoch: 730 | loss: 0.6965547204017639\n",
      "epoch: 740 | loss: 0.6965547204017639\n",
      "epoch: 750 | loss: 0.6965547204017639\n",
      "epoch: 760 | loss: 0.6965547204017639\n",
      "epoch: 770 | loss: 0.6965547204017639\n",
      "epoch: 780 | loss: 0.6965546607971191\n",
      "epoch: 790 | loss: 0.6965546607971191\n",
      "epoch: 800 | loss: 0.6965546607971191\n",
      "epoch: 810 | loss: 0.6965546607971191\n",
      "epoch: 820 | loss: 0.6965546607971191\n",
      "epoch: 830 | loss: 0.6965546607971191\n",
      "epoch: 840 | loss: 0.6965545415878296\n",
      "epoch: 850 | loss: 0.6965546607971191\n",
      "epoch: 860 | loss: 0.6965546607971191\n",
      "epoch: 870 | loss: 0.6965545415878296\n",
      "epoch: 880 | loss: 0.6965545415878296\n",
      "epoch: 890 | loss: 0.6965545415878296\n",
      "epoch: 900 | loss: 0.6965545415878296\n",
      "epoch: 910 | loss: 0.69655442237854\n",
      "epoch: 920 | loss: 0.69655442237854\n",
      "epoch: 930 | loss: 0.69655442237854\n",
      "epoch: 940 | loss: 0.69655442237854\n",
      "epoch: 950 | loss: 0.69655442237854\n",
      "epoch: 960 | loss: 0.69655442237854\n",
      "epoch: 970 | loss: 0.69655442237854\n",
      "epoch: 980 | loss: 0.6965543627738953\n",
      "epoch: 990 | loss: 0.6965543627738953\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    pred = model(X_train)\n",
    "    loss = loss_fn(pred, y_train)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    model.eval()\n",
    "    if epoch % 10 == 0:\n",
    "        with torch.inference_mode():\n",
    "            test_pred = model(X_test)\n",
    "        test_loss = loss_fn(test_pred, y_test)\n",
    "        print(f'epoch: {epoch} | loss: {test_loss}')\n",
    "              "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e49b8e955b2321ae501fb81ec2e04db8bf001ec07b136587f34d18de7e40009d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
